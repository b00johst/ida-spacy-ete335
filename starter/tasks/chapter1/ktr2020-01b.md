---
title: 'KTR 2020 01b'
description:
  'This chapter will teach you even more stuff and help you learn some new
  concepts.'
type: task
location: chapter1
next: ktr2020-01a
prev: ktr2020-01b
id: 202012
---
<exercise id="21" title="Getting Started">



Use Maximum Likelihood estimation with add-one smoothing to estimate theclass probabilities and word probabilities of a Naive Bayes text classifier on the following document collection. Assume that the vocabulary consists of all words in the collection. Answer with fractions.

<table>

<tbody>

<tr>

<th></th>

<th>document</th>

<th>class</th>

</tr>

<tr>

<td>1</td>

<td>Stockholm Oslo</td>

<td>S</td>

</tr>

<tr>

<td>2</td>

<td>Copenhagen Stockholm</td>

<td>D</td>

</tr>

<tr>

<td>3</td>

<td>Stockholm Copenhagen</td>

<td>S</td>

</tr>

<tr>

<td>4</td>

<td>Copenhagen</td>

<td>D</td>

</tr>

</tbody>

</table>

P(S) = <exact-match correct="2/4" right="Bra jobbat!" wrong="Fel svar"></exact-match>

P(Stockholm|S) = <exact-match correct="3/7" right="Bra jobbat!" wrong="Fel svar"></exact-match>

P(Copenhagen|S) = <exact-match correct="2/7" right="Bra jobbat!" wrong="Fel svar"></exact-match>

P(D) = <exact-match correct="2/6" right="Bra jobbat!" wrong="Fel svar"></exact-match>

P(Oslo|D) = <exact-match correct="1/6" right="Bra jobbat!" wrong="Fel svar"></exact-match>

ùëÉ(Copenhagen|S) = <exact-match correct="3/6" right="Bra jobbat!" wrong="Fel svar"></exact-match>


</exercise>


